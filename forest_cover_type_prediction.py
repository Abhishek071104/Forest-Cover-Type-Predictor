# -*- coding: utf-8 -*-
"""Forest-cover-type-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rGbkf7h7wP1tvV6TBpqhRUk9zGD8ANnI
"""

!pip install -q imbalanced-learn scikit-learn pandas numpy joblib

import pandas as pd

# Load dataset
df = pd.read_csv("/content/train.csv")
df.head()

# Confirm there are no nulls
print(df.isnull().sum())

# Drop the target column to separate features
X = df.drop(columns=["Cover_Type"])  # âœ… make sure no extra columns
y = df["Cover_Type"]

print(f"âœ… Number of features in X: {X.shape[1]}")  # Should be 54

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

from imblearn.over_sampling import SMOTE

# Feature Scaling before SMOTE
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# âœ… Save the scaler here, because it's correctly fit on 54 features
import joblib
joblib.dump(scaler, "scaler.pkl")

# Apply SMOTE
sm = SMOTE(random_state=42)
X_train_bal, y_train_bal = sm.fit_resample(X_train_scaled, y_train)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=150, random_state=42)
model.fit(X_train_bal, y_train_bal)

# Save the trained model
joblib.dump(model, "forest_cover_model.pkl")

X_test_scaled = scaler.transform(X_test)
y_pred = model.predict(X_test_scaled)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("\nðŸ“‹ Classification Report:\n", classification_report(y_test, y_pred))
print("\nðŸ§® Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

joblib.dump(model,"forest_cover_model.pkl",compress=1)